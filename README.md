# FastRoLSH

Высокопроизводительная система приближенного поиска ближайших соседей (ANN), реализующая комбинированный подход FastLSH и roLSH для работы с высокоразмерными данными в режиме реального времени.

## О проекте

FastRoLSH — это практическая реализация современного алгоритма приближенного поиска ближайших соседей, сочетающая два подхода:
- **FastLSH**: Снижает вычислительную сложность через случайное семплирование признаков (сложность O(m) вместо O(d))
- **roLSH**: Оптимизирует процесс поиска через адаптивный выбор и расширение радиуса поиска

Система реализована как монолитное серверное приложение с полной поддержкой персистентности состояния, GPU-ускорением и REST API для интеграции с внешними системами.

## Ключевые особенности

- **Поддержка метрик расстояния**: Евклидово расстояние и косинусная мера
- **Инкрементальное обновление**: Возможность добавления данных батчами без перестройки всего индекса
- **Стратифицированное семплирование**: Пропорциональное и сбалансированное семплирование на основе LSH-бакетов
- **Самооптимизация**: Автоматическая настройка параметров на основе характеристик данных
- **Полная персистентность**: Все состояние системы сохраняется в PostgreSQL
- **GPU-ускорение**: Использование PyTorch для эффективных вычислений на GPU

## Архитектура

Система состоит из трех основных компонентов:
1. **PostgreSQL**: Хранилище метаданных, информации о батчах и сериализованного состояния LSH-таблиц
2. **FastAPI сервер**: REST API для взаимодействия с системой и фоновая обработка задач
3. **Вычислительное ядро**: Реализация алгоритмов FastLSH и roLSH на PyTorch

## Быстрый старт

### Запуск через Docker Compose (рекомендуемый способ)

1. Клонируйте репозиторий:
```bash
git clone <https://github.com/Utopialvo/ProdactLSH.git>
cd ProdactLSH
```

2. Запустите систему:
```bash
docker-compose up -d
```

Система будет доступна:
- PostgreSQL: localhost:5432
- FastAPI API: localhost:8000
- Документация API: http://localhost:8000/docs

### Ручная установка

1. Установите зависимости:
```bash
pip install -r requirements.txt
```

2. Настройте PostgreSQL и обновите строку подключения в переменной окружения DATABASE_URL:
```bash
export DATABASE_URL="postgresql://postgres:password@localhost:5432/fast_rolsh_db"
```

3. Инициализируйте базу данных:
```bash
psql -U postgres -d fast_rolsh_db -f init.sql
```

4. Запустите сервер:
```bash
python main.py
```

## Использование API

### Создание датасета

```bash
curl -X POST "http://localhost:8000/datasets/" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "my_dataset",
    "dimension": 100,
    "m": 100,
    "k": 10,
    "L": 5,
    "w": 1.0,
    "distance_metric": "euclidean",
    "initial_radius": null,
    "radius_expansion": 2.0,
    "sampling_ratio": 0.1
  }'
```

### Добавление данных батчами

```bash
curl -X POST "http://localhost:8000/batches/" \
  -H "Content-Type: application/json" \
  -d '{
    "dataset_name": "my_dataset",
    "batch_id": "batch_1",
    "data": [[0.1, 0.2, ...], [0.3, 0.4, ...], ...]
  }'
```

### Поиск ближайших соседей

```bash
curl -X POST "http://localhost:8000/query/" \
  -H "Content-Type: application/json" \
  -d '{
    "dataset_name": "my_dataset",
    "queries": [[0.1, 0.2, ...], [0.3, 0.4, ...]],
    "k": 10
  }'
```

### Стратифицированное семплирование

```bash
curl -X POST "http://localhost:8000/sample/" \
  -H "Content-Type: application/json" \
  -d '{
    "dataset_name": "my_dataset",
    "strategy": "proportional",
    "size": 1000
  }'
```

## Примеры практического использования

В файле `test_file.py` содержатся готовые примеры использования системы для различных задач:

- **Поиск соседей**: Тестирование качества поиска на синтетических данных
- **Кластеризация**: Сравнение кластеризации на полных и семплированных данных
- **Классификация**: Оценка качества классификации на семплированных данных
- **Регрессия**: Тестирование регрессионных моделей на семплированных данных
- **Оптимизация параметров**: Автоматический подбор оптимальных параметров LSH

Запустите тесты для проверки работы системы:
```bash
python test_file.py
```

## API Endpoints

- `GET /` - Информация о API
- `GET /health` - Проверка здоровья сервера и БД
- `POST /datasets/` - Создание нового датасета
- `POST /batches/` - Обработка батча данных
- `POST /query/` - Поиск ближайших соседей
- `POST /sample/` - Семплирование данных
- `GET /datasets/` - Список всех датасетов
- `GET /model/state/{dataset_name}` - Состояние модели
- `POST /model/save/` - Сохранение состояния модели
- `POST /model/load/` - Загрузка состояния модели
- `GET /datasets/{dataset_name}/info` - Информация о датасете
- `GET /datasets/{dataset_name}/batches/{batch_id}` - Информация о батче
- `POST /model/optimize/{dataset_name}` - Оптимизация параметров модели
- `POST /model/update_parameters/{dataset_name}` - Обновление параметров модели

## Структура проекта

```
fastrolsh/
├── main.py                 # Основное FastAPI приложение
├── fast_rolsh_sampler.py   # Реализация алгоритмов FastLSH и roLSH
├── test_file.py            # Тесты и примеры использования
├── init.sql                # Скрипт инициализации БД
├── docker-compose.yml      # Конфигурация Docker Compose
├── Dockerfile              # Dockerfile для сборки образа
├── requirements.txt        # Зависимости Python
└── docs/                   # Документация и теоретические материалы
    ├── LSH.pdf            # Объяснение методологических основ LSH
    ├── FastRoLSH.pdf      # Описание архитектуры системы
    └── IS_LSH.pdf         # Методология Importance Sampling на основе LSH
```

## Особенности реализации

- Состояние LSH-таблиц постоянно сохраняется в PostgreSQL и может быть восстановлено после перезапуска
- Добавление данных выполняется асинхронно через механизм фоновых задач
- Поддержка GPU-ускорения через PyTorch (автоматическое использование CUDA при наличии)
- Реализована эффективная работа с памятью через батчевую обработку

## Примечание о качестве кода

Часть кода была сгенерирована с использованием LLM-моделей. Рекомендуется тщательная проверка и тестирование перед использованием в production-среде. Особое внимание стоит уделить:
- Корректности работы с памятью при больших объемах данных
- Эффективности алгоритмов при высокой размерности данных
- Корректности работы механизма восстановления состояния из БД

## Лицензия

Проект распространяется под лицензией MIT. Подробнее см. в файле LICENSE.